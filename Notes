Kubernetes  is a Open-Source system for Automating the deployment, scaling and management of containerized application.
fEATURES 
  - Conatiner Orchestration:
      Manages Conatines  accross a cluster of maschine.
  - Self-healing:
      Resatrts failed containers, repolace them., Kills unresponsive ones.
  - Sacling:
      Automatically increase/descrease resources based on load
  - Load Balancing :
      Distrub straffic to keep the system responsive.
  - Service Discovery: 
      Makes it easy for services to find and talk each other.
  - Configuration Management: 
      Store and  manages secret and application settings.
_____________________________________________________________________________________

CORE CONCEPT:
  1) Container: 
      Container is the basic unit of software in Kubernetes, packaging applications with their necessary code, libraries, and dependencies.
  2) POD:
      The smalles  deployment unit;
      wraps one or more containers.
  3) Node (server):
      A Single maschine (Physical or virtual) in the cluster.
  4) Cluster:
      A group of nodes managede by Kubernetes.
  5) Deployment:
      Tells Kubernetes how to create and manage Pods.
  6) Service:
      Exposes Pod to the network and handels traffic routing.
_____________________________________________________________________________________
Typical Use Case:
- Bild your app in Dockers container. Then you use Kubernetes to:

1 Deploy the containers across fleet to server.
2 Ensure they stay running.
3 Scale them up during traffic spikes.
4 Roll out new versions without downtime.
_____________________________________________________________________________________
KUBERNETS HAS TWO MAIN PARTS 
  1) MASTER(CONTROL PLANE)
  2) WORKER NODES
_____________________________________________________________________________________

COMPONENETS OF MASTER:

- API Server:
    It Provide the interface (Command line Interface) also known as qubecontrol.
- Schedular:
    Assign node to newly created Pods. ((Pod is a small Unit where the container run it. We have multiple nodes and like to run a new container.
    Which node will be assigned this work has been done by the schedular.)
- ETCD:
    Key value, store having all cluster Data.
    we have all the cluster, Different Nodes, Applications , containers and Pods that store the information ETCD
-  Control Manager
    control Manager is responsible for managing the state of the cluster (When something is damage or kaputt then Control manager repair )
_____________________________________________________________________________________
WORKER NODES

- KUBLET: 
    Agent,make sure that containers are running in Pods.
    (It checks wheather the conatianers are working Properly in the Pods yes or NO)

- POD: 
    the Containers are running in the Pod.
    (Checks that all the conatainers are working Properly  with in the POD)
    A single Instance of a running process in a cluster. It can rum one or more conatiners and share the same resources.

- Kube-Proxy:
    Maintain the Network rules for communication with POds.
    eg. we have a cluster, we have inside Network, we have Outside Network, There are many Pods running in the NOde(to run/Maintain all the Things we use Kube-Proxy. 

- Container-runtime:
    A tool is responsible for running containers er. Dockers 
    
_____________________________________________________________________________________
Difference between Docker and the ConatinerD



_____________________________________________________________________________________
ETCD:


_____________________________________________________________________________________
NOTE: if we not move a one pod from one node to another node.
      we can only delete the pod and create a new pod on anothe node where u want 


F: How to get the help for the commands 
    kubectl run --help
F: On which image used to create the new Pods?
    kubectl describe pod newpodname 
    kubectl  get pods-o wide 
F: How many containers are in the pod 
    kubectl describe pod 
F: Why do you think the computer agenty in pod webapp is in error

F: What does the READY column in the output of the kubectl get Pods commans indicate 
    1/2  Running container in PODS/Total container in POD 
F: 
F: How to create the Pods?
    kubectl run ngnix --image=ngnix

F:  How to delete the pod?
      kubectl delete pod webapp
      kubectl delete pods --all 
F: How to make the change in the pod?
      kubectl edit pod podname
F: How to Create a new Pod with the name of the rednis and with the image rednis123?
   Note: Use the POD-Defination YaAML file. And yes the image name is wrong
    kubectl run rednis --image=rednis123 --dry-run -o yaml
    kubectl run rednis --image=rednis123 --dry-run=client -o yaml
    kubectl run rednis --image=rednis123 --dry-run=client -o yaml > rednis.yaml
    cat rednis.yaml

--dry-run: It is only used to check th command wheather it is right or wrong and this is the 
  clint side command. The request will not go to the server 


Note: Use the POD-Defination YaAML file. And yes the image name is wrong
a) how to create a yaml file 
    kubectl create -f rednis.yaml
b) see weather thepod s file is created or not 
    kubectl get pods


F: How to change the image on this pod to rednis. Once done, the pod should be in a running state?
    cat redis.yaml
    vi redis.yaml
    kubectl applay -f rednis..yaml
    kubectl get pods

F: How to show the labels 
    kubectl describe pod rednis
    kubectl describe pod --show-labels 

--dry-run: It is only used to check th command wheather it is right or wrong and this is the 
  clint side command. The request will not go to the server 

 

____________________________________________________________________

A ReplicationController is a legacy Kubernetes controller that ensures a specified number of pod replicas are running at any given time.

--Function of replicaController
    Automatically replaces failed pods
    Ensures the desired number of pods are always running  
    Used in earlier versions of Kubernetes

-REPlication Controller:(what and Why we need this)
    - Replication controller helps us to run multiple instances of a single pod in the kubernetes cluster,
      thus providing high availability.
    - Replication controller can help by automatically bringing up a new pod when existing one fails
      thus the replication controller ensure that the specified numbers of pods are running all the times
      even it 1 or 100

NOTE: we can also use the replication controller when we use the one pod not only multiple pods 
There are two similar terms(same perpouse but not same)
1) Repelation Controller: is the older technology that is replaced by Replica Set 

2) Replica Set: is the new Recomended way to set up replication.

- How to create a Replication Controller defination file 
    rc-defination.yml
- As we any kubernets defination file we have 4 section
  1)  API version 
  2)  Kind
  3)  Metadata 
  4)  Specification  but written as spec NOTE we cn tested the two defination file together 

1) API version: is specific to what we are creating 
2) Kind : As we know oit is Replacation Controller.
3) Meta Data: Add Name, Labels, app type and assign values to them 
4) spec. What is inside the object we are creating.
NOTE: we can copy from the pod -defination file the data into/under the spec template  
____________________________________________________________________
                          LAB 2 Replication controller

F: How to create the Replication  Controller
    kubectl create -f rc-defination.yml 
F: How to see the Replication Controller list 
    kubectl get replicationcontroler 
F: How many Pods are created by the replication Controller
    kubectl get pods
____________________________________________________________________
REPLICA_SET
    A ReplicaSet is the newer version of ReplicationController that 
    also ensures a specified number of pod replicas are running continuously, 
    
    but with more powerful and flexible label selectors.

there is only one differencence between replication controller and Replica set 
- Replica Set requires a selector defination the selector section helps the Replica Set 
  identify what pods fall under it.

Festures of the Replica Set 
    Same purpose as RC: maintain a stable number of pods
    Supports set-based label selectors
    Commonly used as part of a Deployment

- In Replica set there are three sections 
    1) Template 
    2) replicas 
    3) Selector 

_____________________________________________________________________


____________________________________________________________________
                            LAB Replica Set 

F: How to create the Replica Set
    kubectl create -f replicaset-defination.yml 
F: How to see the Replic set list 
    kubectl get replicaset 
F: How to create a Pod in the replicaSet?
    kubectl describe replicaset
F: How to delete the Replicaset Pod
    kubectl delete replicaset myapp-replioaset
    (Also delete all Underlying pod)
F: How to replace and update the Replica set
    Kubectl replace -f relicaset-defination.yml
F: How to kube control scale command to scale the Replicaset 
    kubectl scale -replicas=6 -f replicaset-defination.yml
F: How to check the apiversion of replicaset 
    kubectl api-resources | grep replicaset
F: 
____________________________________________________________________

                        LABELS AND SELECTORS 

         
____________________________________________________________________
                    LAB  Lables and Selsctors  
F: How to create an Labels 
       kubectl describe pod nginx | less
F: How to attach the new Labels 
      kubectl label pod nginx env=testing 
F: How to overright the label 
      kubectl label --overwrite pod ngnix env=prod
F: How to delete the Label
      kubectl label pod ngnix env-
F: How to see/display the Labels 
      kubectl get pods --show-labels 


____________________________________________________________________
                    DEPLOYMENT

Deployment is used to manage the automatic life cycle of the pods. 
It create updates scaling and rollback of the Instances when any eroor occur
NOTE: Deployment create an Replicaset automaticall. When we run
      kubectl get replicaset
      You will see the replicaset file.


Features of the Deployment
1. Manages Replica Pods
    It makes sure that a specified number of Pods are always running.
2. Self Healing
    If a pod crashes or gets deleted, the Deployment will automatically create a new one to replace it.
3. Rolling Updates
      You can update your application image or configuration, and the Deployment will roll out changes gradually with zero downtime.
4. Rollback support 
      If something goes wrong during an update, you can easily rollback to a previous stable version.

_____________________________________________________________________
              How to create a Deployment file 
- The Deployment file is same like a Replicaset 
    only in Kind: DEPLOYMENT
- Contents of the File
    API Version:
    Metadata: 
      name 
      labels
    spec:
        template:
          metadata:
          
    replica: 
    selector:
_____________________________________________________________________
              LAB 3 deployment

F: How many pods are created
      kubectl get POD 
F: HOw many replica set are created 
      kubectl get rs
F: HOw many deployments are created 
      kubectl get deployments
F: How many deployments exists on the system. We just creaed a one Deployment 
      kubectl get deployments 
F: How many rs are created
      kubectl get rs
F: How many PODS are created 
      kubectl get Pod
F: Out of all the PODs how many are READY
      kubectl get deployments 
F: What is the image used to create the POD in the new deployments 
      kubectl describe pod frontend-deployment-7fd8cdb696-stmbx  
F: Create a new Deployment using the deployment-definition-1.yaml file located at /root/.
A:    pwd (to go to the root)
      ls (see the list of the deployments files)
      kubectl create -f deployment-defination-1.yaml (to create a yaml file on the root)
      vi deployment-defination-1.yaml ( to make the changes on the yaml file)
      kubectl create -f deployment-definition-1.yaml (to create a .yaml file on the root)

 
F: Create a new Deployment with the bwlow attributes using your own deployment defination file 
    NAME : http-frontend:
    replica: 3 
    image:httpd:2.4-alpine
A:  kubectl create  deployment --help ( to get the help of the deployments commands)
    kubectl create deployment httpd-frontend --image=httpd:2.4-alpine --replica=3

NOTE: If u forget to create a replica then use 
      kubectl scale deployment httpd-frontend --replicas=3


_____________________________________________________________________


            Kubernetes services
Kubernetes services enable the communication betwen the various components and with in the outside the application 
it helps us to connect applications together
-- typically using a stable DNS name and IP address.


Types of services

  1) NodePort
  2) ClusterIP
  3) LoadBalancer 

Curl: Curl is used to talk with the AIP server (u can send or get the data from the networl
curl is a command-line tool for transferring data to or from a server using protocols like HTTP, HTTPS, etc.

 1) Why we need Services?

    - Pods are temporary â€” they can die, restart, or be replaced.
    - Each Pod gets a unique IP, which may change.
    - A Service provides a stable way to reach Pods, regardless of changes in the underlying Pod IPs.

2) Types of Services:

    - ClusterIP (default): Exposes the Service on an internal IP in the cluster. Accessible only within the cluster.
    - NodePort: Exposes the Service on a static port on each Nodeâ€™s IP. Allows external traffic to access the Service via <NodeIP>:<NodePort>.
    - LoadBalancer: Uses a cloud provider's load balancer to expose the Service externally.
    - ExternalName: Maps a Service to a DNS name (e.g., external database).

3) How Services Work:

    -  A Service uses labels to find the set of Pods it targets.
    -  For example, if all backend Pods have a label app=backend, the Service will route traffic to all matching Pods.

4) DNS Names in Kubernetes:

    - Services are automatically assigned a DNS name.
    - For example, a Service named db-service in the marketing namespace can be accessed at:
          db-service.marketing.svc.cluster.local
5) Ports:

    - Services define a port to expose and optionally a targetPort (the port on the Pod).
    - Example: A Redis Service might expose port 6379.

NOTE: If an application wants to connect to a Redis database, it doesnâ€™t need to know the IP of the Redis Pod.
      It just connects to redis-service:6379, and the Service routes traffic to the correct Pod(s).

________________________________________________________________
                LAB 4 Services

F: How many Services exist on the system?
   In the current(default) namespace
A:   Kubectl get service
     kubectl get svc

F: What is the type of the default kubernetes service?
      kubectl get svc

F: What is the targetport configured on the kubernetes service?
      kubectl describe svc kubernetes

F: How many labels are configured on the kubernetes service?
     kubectl describe svc kubernetes

F: How many Endpoints are attached on the kubernetes service?
    kubectl describe svc kubernetes

F: How many Deployments exist on the system now?
   In the current(default) namespace
    kubectl get deploy

F: What is the image used to create the pods in the deployment?
      kubectl describe deploy simple-webapp-deployment


Create a new service to access the web application using the service-definition-1.yaml file.
Name: webapp-service
Type:       NodePort
targetPort: 8080
port:       8080
nodePort:   30080
selector:
 name:      simple-webapp

A:  ls
    cat service-defination-1.yaml
    vi  service-defination-1.yaml'(update the file) 
    kubectl create -f service-defination-1.yaml
    
   _____________________________________________________________________
What is a Namespace in Kubernetes?
    A namespace is a way to divide a Kubernetes cluster into multiple virtual environments,(separate, logical parts)
    like creating separate compartments for different teams, projects, or applications.

F: Why use Namespaces?
   - To separate environments (e.g., dev, test, prod)
   - To manage multiple teams or projects in one cluster
   - To apply resource limits and access control per group

1) Isolation:(à¤µà¤¿à¤­à¤¾à¤œà¤¨ à¤”à¤° à¤…à¤²à¤—à¤¾à¤µ)
    - Namespaces provide logical isolation between groups of resources (like Pods, Services, Deployments).
    - For example, two teams can each have a web-app running in separate namespaces (team-a and team-b) without interfering with each other.

2) Resource Scoping:
    - Most Kubernetes resources (like Pods, Services, ConfigMaps) live within a namespace.
    - Some resources (like Nodes, PersistentVolumes) are not namespaced.

3) Access Control:
    - Role-Based Access Control (RBAC) rules can be applied per namespace, giving fine-grained permissions.

4) Resource Quotas:
    - Namespaces can have quotas (CPU, memory, number of objects) to prevent one team from using up all cluster resources.

5) Default Namespace:
    - If you donâ€™t specify a namespace, Kubernetes uses the default namespace.
______________________________________________________________________
              LAB 5 Namespaces 

F: How many Namespaces exist on the system?
      kubectl get namespaces 
      kubectl get ns

F: How many pods exist in the research namespace?
      kubectl get pods --namespace=research
      kubectl get pods --n=research

F: Create a POD in the finance namepsace. Use the spec given below
      kubectl run redis --image=redis -n=finance
    

F: To see wheather the pod is created in the finance
      kubectl get pod -n=finance

F: Which namespace has the blue POD in it?
      kubectl get ns 
      kubectl get pods  --all-namespaces (this is used to display the namespaces AND all the pods
      kubectl get pods -A

F: What DNS Name should the Blue application use to access the database db-service in its own namespace-marketing
   You can try it in the web application UUUI. USe port 6379
      kubectl get pods -n=marketing
      kubectl get svc -n=marketing

F: What DNS Name should the Blue application use to access the database 'db-service' in the devnamespace
   You can try it in the web application UUUI. USe port 6379
      kubectl get svc -n=dev
      

__________________________________________________________

Imperative und Declarative 



__________________________________________________________
                LAB 6 (Impariative Commands)
F: Deploy a pod named nginx-pod using the nginx:alpine image.
      kubectl run nginx-pod --image=nginx:alpine

F: Deploy a redis pod using the redis:alpine image with the labels set to tier=db.
      kubectl run redis --image=redis:alpine --labels="tier=db"

F: Create a service named redis-service to expose the existing redis pod within the cluster on port 6379.
      kubectl expose pod redis --port 6379 --name redis-service
      kubectl get svc

F: Create a deployment named webapp using the image kodekloud/webapp-color with 3 replicas.
       kubectl create deployment webapp --image=kodekloud/webapp-color --replicas=3
       kubectl get deploy

F: Create a new pod called custom-nginx using the nginx image and run it on container port 8080.
       kubectl run custom-nginx --image=nginx --port=8080

F: Create a new namespace called dev-ns.
        kubectl create namespace dev-ns

F: Create a new deployment called redis-deploy in the dev-ns namespace with the redis image. It should have 2 replicas.
        kubectl create deployment redis-deploy --image=redis --replicas=2 -n  dev-ns
        kubectl get deployment -n dev-ns

F: Create a pod named httpd using the image httpd:alpine in the default namespace.
Then, create a service of type ClusterIP with the same name (httpd) that exposes the pod on port 80.
      kubectl run httpd --image=http:alpine --port 80 --expose=true 
__________________________________________________________________

Chapter 2 Schudeling 

LAB 7

NOTE When u want to schedule the port means(u delete the pod from one Node to another)
      Youu habe to do 4 steps 
        kubectl get pods 
        Kubectl get pods -o wide(to see in which node is the pod)
        vi nginx.yaml(open the pod and change the node name Manually and save it)
        kubectl replace --force -f nginx.yaml(delete the pod pod from one node and create a new pod to another node)
                                             (this command delete the data from the pod )
                                             ( when we want that the data wilkl not be deleted we have to use  Persistent Volume (PV) )

F: A pod definition file nginx.yaml is given. Create a pod using the file.
   Only create the POD for now. We will inspect its status next.
      kubectl get pods
      ls (to see the files)
      cat nginx.yaml (display all the data from the file)
      kubectl create -f nginx.yaml (to create a pod though the file)
      kubectl get pods

F: What is the status of the created POD?
      kubectl get pods 

F: Why the pod is the pending state?
   Inspect the environment for various kubernetes control plane components.
A:    kubectl describe pod nginx
      kubectl get pods -n kube-system

F: Manually schedule the pod on node01.
   Delete and recreate the POD if necessary.
      ls
      vi nginx.yaml (make changes nodeName: node01)
      kubectl get pods 
      kubectl  get pods --watch (to watch the pods wheather it make any changes )
      kubectl replace --force -f n
F: Now schedule the same pos on the controlplane node
   Delete and recreae the pod if necessary
      kubectl get pods 
      vi nginx.yaml(make the changes) 
      kubectl replace --force -f nginx.yaml
      kubectl get pods
      kubectl get pods -o wide 

      _________________________________________________________________________________
                    Labels and selectors  LAB  7

F: We have deployed a number of PODs. They are labelled with tier, env and bu. How many PODs exist in the dev environment (env)?
   Use selectors to filter the output
        kubectl get pods 
        kubectl get pods --selector env=dev 
        kubectl get pods --selector env=dev | wc -l (it display number of lines with header)
        kubectl get pods --selector env=dev --no-headers| wc -l(it display the nummber of lines without header)
NOTE: first  label=podName 
             env=dev 

F: How many PODs are in the finance business unit (bu)?
        kubectl get pods --selector bu=finance --no-header | wc -l

F: How many objects are in the prod environment including PODs, ReplicaSets and any other objects?
        kubectl get all  --selector env=prod --no-header | wc -l
NOTE all is use to see all the obejects are created in the environment prod


F: Identify the POD which is part of the prod environment, the finance BU and of frontend tier?
        kubectl get all --selector env=prod,bu=finance,tier=frontend

F: A ReplicaSet definition file is given replicaset-definition-1.yaml. Attempt to create the replicaset; you will encounter an issue with the file. Try to fix it.
  Once you fix the issue, create the replicaset from the definition file.
        ls
        cat replicaset-definition-1.yaml 
        kubectl create -f replicaset-definition-1.yaml 
        vi replicaset-definition-1.yaml (change the name of the tierName in the selector)
        kubectl create -f replicaset-definition-1.yaml
        kubectl get rs

___________________________________________________________________
tant and tolaration:

tant and tolerations areused to set the restrictions.
On which Node the pod can be scheduled

Tains and toleration doesnot tell the pod to go to a particuler Node,
instead tell the node to accept only pods with certain tolerations
NOTE: 
the tanits are set on Nodes.
the toleration are set on the Pods
Now the 

Syntax:   kubectl taint nodes name key=value:taint-effect
eg.       kubectl taint nodes node1 app=blue:Noschedule

1) taint-effect: 
    defines what would be happend to the pods, if they do not tolerates the taint there are three taint effects.
    - NoSchedule:
      Which means that the pod will not be scheduled on the node.
    - PreferNOSchedule:
      Which means the system willl try to avoid placing a pod on the nodes and that is no gauranted.
    - NoExectute:
      Which menas that the new pod will not be scheduled on the node and existing pods on the node. if any will be evicted
      means they do not tolerate the taints 

Toleration :
      Tolaration are added to pods. To add the toleration to pods first pull the defination file and change the tolerations: under spec:
      How to write in the file:
      toleration: 
      key:"app"
      operator: "Equal"
      value:"blue"
      effect: "NoSchedule"

F:   how to see wheather the tent are attached there 
     kubectl describe nodes worker01 | less 
__________________________________________________________________
      Lab 8 Taint and toleration 

 F: How many nodes exist on the system?
    Including the controlplane node.
 A:    kubectl get nodes

 F: Do any taints exist on node01 node?
 A:     kubectl describe node node01

F: Create a taint on node01 with key of spray, value of mortein and effect of NoSchedule
A:      kubectl taint node node01 spray=mortein:NoSchedule
        kubectl describe node node01  (to check wheather the taints are created are not)

F:  Create a new pod with the nginx image and pod name as mosquito.
A:      kubectl run mosquito --image=nginx

F: What is the state of the POD?
A:      kubectl get pods

F:  Why do you think the pod is in a pending state?
A:      kubectl describe pod mosquito

F: Create another pod named bee with the nginx image, which has a toleration set to the taint mortein.
   Image name: nginx
   Key: spray
   Value: mortein
   Effect: NoSchedule
   Status: Running

A:      kubectl run bee --image=nginx --dry-run=client -o yaml
        kubectl run bee --image=nginx --drs-run=client -o yaml > bee.yaml (recreate a file)
        vi bee.yaml
              tolerations:  
               - key: spray
               value: mortein
               effect: NoSchedule
               operator: Equal
        kubectl create -f bee.yaml

F: Observe that the bee pod has been scheduled on node node01 due to the toleration that has been configured for the pod.
        kubectl get pods 
        kubectl get pods --watch

F: Do you see any taints on controlplane node?
A:       kubectl describe pod controlplane

F: Remove the taint on controlplane, which currently has the taint effect of NoSchedule.
A:       kubectl taint node controlplane node-role.kubernetes.io/control-plane:NoSchedule-

F: What is the state of the pod mosquito now?
         kubectl get pods 

F: Which node is the POD mosquito on now?
          kubectl get pods -o wide


__________________________________________________________
Node Selector 
  A node selector is a simple way to tell a Pod which nodes it can run on based on labels.
      Nodes have labels (e.g., disktype=ssd).
      Node selector in a Pod specifies these labels.
      Kubernetes will schedule the Pod only on nodes matching those labels.

We can select the pods that the pod run only on the specific nodes: there are two ways to doe that
1) Using the node selector (Simple and eiser method)
    - open the pod defination yaml file 
    -  to limt this pod we add a new propertie as a     nodeSelector  under spec: section
    -  you have to write nodeSelector: Large (where the large comes from)
    -  you have to declare the large as a label and selector 
    -  to specify the labels on the Nodes 

Syntax:      Kubectl label nodes <node-name> <label-key> = <label-value>
eg:          lubectl label nodes node-1 size=Large

    - this is very simple example What is when we want to put the pod on the not small and not on the large Node
      In this case we have to use NODE AFFINITY
------------------------------------------------------
NODE AFFINITY:

Node Affinity is used to control which nodes a Pod can be scheduled on--- based on the labels assigned on the nodes.
This is the best to tell the Kubernetes Scheduler.
eg i want this pod run on the nodes that  matches the things(location , speicher, hardware.......)

ðŸ”¸ How is it Different from nodeSelector?

Feature	            nodeSelector	            nodeAffinity
Type	              Simple key-value match	  Advanced expressions supported
Flexibility	        Limited	                  More flexible (AND, OR, ranges)
Priority Support	  No	                      Supports soft rules (preferred)


ðŸ”¸ Types of Node Affinity
1) requiredDuringSchedulingIgnoredDuringExecution(Hard rule)
        Pod will not be scheduled if node doesn't match
        Once running, the rule is ignored

-------   DuringScheduling: is the state where a pod does not exist and created for the first time.

F: What happend what if the nodes  with matching labels are not available or forgot it ?
A: now i have to use the node Affinity. If i used 
    1) requiredDuringSchedulingIgnoredDuringExecution  (Hard rule)
        the Scheduler will mandate that the pod be placed on a node with the given affinity rules 
        if it cannot find one, the pod will not be scheduled.
NOTE: this type is ued when the placement of pod is crucial. if the maching nodes does not exists the pod will not be scheduled.


---- if the placement of Pod is less important than running the workload itself in the t case we used
    2)  preferredDuringSchedulingIgnoredDuringExecution   (Soft rule)
          where the matching node is not found. the Scheduler will not simply ignore node affinity rules and place the pod of any node.
NOTE: this is the way to tell the scheduler 

---------- DuringExecution:  is a state where the pod has been running and a chane is mede in the Environment that affects on the node affinity 
          Such as change in the label of the node.
eg. Some one remove the label, but we are not able to change the labels on the Node.

---- if you want to change any Pod that are running on Nodes 

        Kubernetes tries to schedule to a matching node, but can skip if none match

3)  requiredDuringSchedulingRequiredDuringExecution (not stable)
        Rule is enforced both at scheduling and runtime

